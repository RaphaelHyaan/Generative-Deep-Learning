{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM on chinese-poetry/ci.song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device =  torch.device('cuda')\n",
    "VOCAB_SIZE = 10000\n",
    "MAX_LEN = 200\n",
    "EMBEDDING_DIM = 100\n",
    "N_UNITS = 128\n",
    "VALIDATION_SPLIT = 0.2\n",
    "SEED = 42\n",
    "LOAD_MODEL = False\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "JSON_DIR = 'C:/Users/Raphael/OneDrive/备份/桌面/大学生活和学习/教材/深度学习/Generative-Deep-Learning/datas/chinese-poetry/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoetryDataSet(Dataset):\n",
    "    def __init__(self, json_dir = JSON_DIR):\n",
    "        songci_data = []\n",
    "        # 获取目录下的所有文件\n",
    "        for filename in os.listdir(json_dir):\n",
    "            # 检查文件是否为json文件\n",
    "            if filename.endswith('.json'):\n",
    "                filepath = os.path.join(json_dir, filename)\n",
    "                # 打开并加载json文件\n",
    "                with open(filepath, 'r', encoding='utf-8') as json_data:\n",
    "                    data = json.load(json_data)\n",
    "                    for item in data:\n",
    "                        songci_data.append(item)\n",
    "        self.songci_data = songci_data\n",
    "        self.filtered_data = [x[\"rhythmic\"]+':'+''.join(x[\"paragraphs\"]) for x in songci_data]\n",
    "        self.n_songci = len(self.filtered_data)\n",
    "        self.max_len = max(len(data) for data in self.filtered_data)  # 获取最大长度\n",
    "        \n",
    "        # 构建字符到索引的映射\n",
    "        self.chars = sorted(list(set(''.join(self.filtered_data))))\n",
    "        self.c2i = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.i2c = dict((i, c) for i, c in enumerate(self.chars))\n",
    "        \n",
    "        self.indexed_data = []\n",
    "        for data in self.filtered_data:\n",
    "            indexed_data = [self.c2i[c] for c in data]\n",
    "            # 使用0填充到最大长度\n",
    "            indexed_data += [0] * (self.max_len - len(indexed_data))\n",
    "            self.indexed_data.append(indexed_data)\n",
    "        self.indexed_data = torch.tensor(self.indexed_data)\n",
    "\n",
    "    def print_example(self):\n",
    "        index = np.random.randint(0, self.n_songci)\n",
    "        print(self.filtered_data[index])\n",
    "        print(self.indexed_data[index])\n",
    "    \n",
    "    def put_i2c(self):\n",
    "        return self.i2c\n",
    "    \n",
    "    def put_c2i(self):\n",
    "        return self.c2i\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_songci\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.indexed_data[idx,:-1].cuda(),self.indexed_data[idx,1:].cuda()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poetrydataset = PoetryDataSet()\n",
    "poetrydataset.print_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "        self.lstm = nn.LSTM(EMBEDDING_DIM, N_UNITS, batch_first=True)\n",
    "        self.fc = nn.Linear(N_UNITS, VOCAB_SIZE)\n",
    "        self.activation = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.fc(x)\n",
    "        outputs = self.activation(x)\n",
    "        return outputs\n",
    "\n",
    "    def train_model(self,poetrydataset):\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        for epoch in range(EPOCHS):\n",
    "            for batch_idx, (data, target) in enumerate(poetrydataset):\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.forward(data)\n",
    "                loss = loss_function(outputs.view(-1, VOCAB_SIZE), target.view(-1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if batch_idx % 100 == 0:\n",
    "                    print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx, len(poetrydataset),\n",
    "                        100. * batch_idx / len(poetrydataset), loss.item()))\n",
    "    def save(self):\n",
    "        torch.save(self.state_dict(), 'model.pth')\n",
    "    def load(self):\n",
    "        self.load_state_dict(torch.load('model.pth'))\n",
    "    def generate(self, start_prompt,c2i,i2c, max_tokens = 200, temperature = 1):\n",
    "        '''生成文本\n",
    "        参数：\n",
    "            start_prompt: 起始文本\n",
    "            max_tokens: 生成文本的最大长度\n",
    "            temperature: 控制文本生成的创造性，值越大生成的文本越有创造性，值越小生成的文本越固定        \n",
    "        '''\n",
    "        start_tokens = [c2i.get(x, 1) for x in start_prompt.split()]\n",
    "        sample_token = None\n",
    "        info = []\n",
    "        while len(start_tokens) < max_tokens:\n",
    "            x = torch.tensor([start_tokens]).to(device)\n",
    "            y = self.forward(x)\n",
    "            y = y.detach().cpu().numpy()\n",
    "            sample_token, probs = self.sample_from(y[0][-1], temperature)\n",
    "            info.append({\"prompt\": start_prompt, \"word_probs\": probs})\n",
    "            if sample_token > len(i2c):\n",
    "                sample_token = 0\n",
    "            start_tokens.append(sample_token)\n",
    "            \n",
    "            start_prompt = start_prompt + \" \" + i2c[sample_token]\n",
    "        print(f\"\\ngenerated text:\\n{start_prompt}\\n\")\n",
    "        return info\n",
    "    def sample_from(self, probs, temperature):  # <2>\n",
    "        # probs = probs ** (1.0 / temperature)\n",
    "        # probs = probs / np.sum(probs)\n",
    "        return np.random.choice(len(probs), p=probs), probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTMModel().cuda()\n",
    "\n",
    "dataloader = DataLoader(poetrydataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "lstm.train_model(dataloader)\n",
    "\n",
    "lstm.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.generate('水调歌头:明月几时有，把酒问青天',poetrydataset.put_c2i(),poetrydataset.put_i2c(),100,0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
