{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Condition WGAN-GP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('C:/Users/Raphael/OneDrive/备份/桌面/大学生活和学习/教材/深度学习/Generative-Deep-Learning')\n",
    "from utiles import display\n",
    "device =  torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64\n",
    "CHANNELS = 3\n",
    "CLASSES = 2\n",
    "BATCH_SIZE = 128\n",
    "Z_DIM = 32\n",
    "LEARNING_RATE = 0.00005\n",
    "ADAM_BETA_1 = 0.5\n",
    "ADAM_BETA_2 = 0.999\n",
    "EPOCHS = 20\n",
    "CRITIC_STEPS = 3\n",
    "GP_WEIGHT = 10.0\n",
    "LOAD_MODEL = False\n",
    "ADAM_BETA_1 = 0.5\n",
    "ADAM_BETA_2 = 0.9\n",
    "LABEL = \"Blond_Hair\"\n",
    "LABEL_DIR = \"C:/Users/Raphael/OneDrive/备份/桌面/大学生活和学习/教材/深度学习/Generative-Deep-Learning/chapter_4/list_attr_celeba.csv\"\n",
    "IMG_DIR = \"C:/Users/Raphael/OneDrive/备份/桌面/大学生活和学习/教材/深度学习/Generative-Deep-Learning/datas/img_align_celeba\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BHDataset(Dataset):\n",
    "    def __init__(self, img_dir, label, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.attributes = pd.read_csv(LABEL_DIR)\n",
    "        self.labels = self.attributes[label]\n",
    "        # print(self.labels)\n",
    "        self.int_labels = np.where(self.labels == 1, self.labels, 0)\n",
    "        # print(self.int_labels)\n",
    "        self.img_names = os.listdir(img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_names[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = torch.tensor(self.int_labels[idx]).cuda()\n",
    "        if self.transform:\n",
    "            image = self.transform(image).cuda()\n",
    "        return image, label\n",
    "\n",
    "# 定义预处理函数\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: (x * 255.0 - 127.5) / 127.5),\n",
    "])\n",
    "\n",
    "# 读入数据\n",
    "train_data = BHDataset(img_dir=IMG_DIR, \n",
    "                                label=LABEL, \n",
    "                                transform=preprocess)\n",
    "\n",
    "# 创建一个DataLoader实例\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 展示一些数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载一些图像\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "real_batch_images = images[0:10]\n",
    "real_batch_label = labels[0:10]\n",
    "\n",
    "real_batch_images = np.transpose(torch.squeeze(real_batch_images).cpu().numpy(),(0,2,3,1))\n",
    "\n",
    "# 展示\n",
    "display(real_batch_images, cmap=\"gray_r\", as_type=\"float32\")\n",
    "\n",
    "# 加载并展示一些棕色头发的图像\n",
    "blond_hair_images = images[labels == 1]\n",
    "blond_hair_images = np.transpose(torch.squeeze(blond_hair_images[0:10]).cpu().numpy(),(0,2,3,1))\n",
    "display(blond_hair_images, cmap=\"gray_r\", as_type=\"float32\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立评价者模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(CHANNELS + 1, 64, kernel_size=4, stride=2, padding=1)\n",
    "        self.leaky_relu1 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
    "        self.leaky_relu2 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.conv3 = nn.Conv2d(128, 128, kernel_size=4, stride=2, padding=1)\n",
    "        self.leaky_relu3 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.conv4 = nn.Conv2d(128, 128, kernel_size=4, stride=2, padding=1)\n",
    "        self.leaky_relu4 = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.conv5 = nn.Conv2d(128, 1, kernel_size=4, stride=1, padding=0)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, critic_input, label_input):\n",
    "        x = torch.cat([critic_input, label_input], dim=1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.leaky_relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.leaky_relu2(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.leaky_relu3(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.leaky_relu4(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.flatten(x)\n",
    "        return x\n",
    "\n",
    "# 创建模型实例\n",
    "critic = Critic().cuda()\n",
    "print(critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载一些数据用于测试模型\n",
    "test_data_iter = iter(train_loader)\n",
    "test_images, test_labels = next(test_data_iter)\n",
    "test_labels = torch.unsqueeze(torch.unsqueeze(torch.unsqueeze(test_labels, 1),1),1)\n",
    "test_labels = test_labels.expand(-1,-1,IMAGE_SIZE,IMAGE_SIZE)\n",
    "critic.eval()\n",
    "with torch.no_grad():\n",
    "    critic_output = critic(test_images, test_labels)\n",
    "# print(critic_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成器模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Linear(Z_DIM + 1, 128)\n",
    "        self.conv1 = nn.ConvTranspose2d(128, 128, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "        self.conv2 = nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.ConvTranspose2d(128, 128, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.ConvTranspose2d(64, CHANNELS, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, generator_input, label_input):\n",
    "        x = torch.cat([generator_input, label_input], dim=1)\n",
    "        x = self.fc(x)\n",
    "        x = x.view(x.size(0), 128, 1, 1)\n",
    "        x = self.leaky_relu(self.bn1(self.conv1(x)))\n",
    "        x = self.leaky_relu(self.bn2(self.conv2(x)))\n",
    "        x = self.leaky_relu(self.bn3(self.conv3(x)))\n",
    "        x = self.leaky_relu(self.bn4(self.conv4(x)))\n",
    "        x = torch.tanh(self.conv5(x))\n",
    "        return x\n",
    "\n",
    "# 创建模型实例\n",
    "generator = Generator()\n",
    "print(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试模型\n",
    "generator_input = torch.randn(BATCH_SIZE, Z_DIM)\n",
    "label_input = torch.randn(BATCH_SIZE, 1)\n",
    "\n",
    "generator.eval()\n",
    "with torch.no_grad():\n",
    "    output = generator(generator_input, label_input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CGAN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalWGAN(nn.Module):\n",
    "    def __init__(self,critic,generator,latent_dim,critic_step,gp_weight):\n",
    "        '''初始化模型'''\n",
    "        super(ConditionalWGAN, self).__init__()\n",
    "        self.critic = critic\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.critic_step = critic_step\n",
    "        self.gp_weight = gp_weight\n",
    "        self.c_optimizer = optim.Adam(self.critic.parameters(),lr=LEARNING_RATE,betas=(ADAM_BETA_1,ADAM_BETA_2))\n",
    "        self.g_optimizer = optim.Adam(self.generator.parameters(),lr=LEARNING_RATE,betas=(ADAM_BETA_1,ADAM_BETA_2))\n",
    "        self.generated_images = []\n",
    "\n",
    "    def forward(self,real_images,labels):\n",
    "        '''前向传播'''\n",
    "        batch_size = real_images.shape[0]\n",
    "        random_latent_vectors = torch.randn((batch_size, self.latent_dim)).cuda()\n",
    "\n",
    "        generated_labels = torch.unsqueeze(labels,1)\n",
    "        generated_images = self.generator(random_latent_vectors, generated_labels)\n",
    "\n",
    "        critic_labels = torch.unsqueeze(torch.unsqueeze(torch.unsqueeze(labels, 1),1),1)\n",
    "        critic_labels = critic_labels.expand(-1,-1,IMAGE_SIZE,IMAGE_SIZE)\n",
    "        real_predictions = self.critic(real_images,critic_labels)\n",
    "        fake_predictions = self.critic(generated_images,critic_labels)\n",
    "\n",
    "        return real_predictions, fake_predictions, generated_images\n",
    "\n",
    "    def gradient_penalty(self, real_images, generated_images, labels):\n",
    "        '''计算梯度惩罚'''\n",
    "        batch_size = real_images.shape[0]\n",
    "        alpha = torch.rand((batch_size,1,1,1)).cuda()\n",
    "\n",
    "        interpolated_images = real_images + alpha * (generated_images - real_images)\n",
    "        interpolated_labels = torch.unsqueeze(torch.unsqueeze(torch.unsqueeze(labels, 1),1),1)\n",
    "        interpolated_labels = interpolated_labels.expand(-1,-1,IMAGE_SIZE,IMAGE_SIZE)\n",
    "\n",
    "        mixed_scores = self.critic(interpolated_images,interpolated_labels)\n",
    "\n",
    "        gradient = torch.autograd.grad(\n",
    "            inputs=[interpolated_images],\n",
    "            outputs=[mixed_scores],\n",
    "            grad_outputs=torch.ones_like(mixed_scores),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )[0]\n",
    "\n",
    "        gradient = gradient.view(gradient.shape[0], -1)\n",
    "        gradient_norm = gradient.norm(2, dim=1)\n",
    "        gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "        return gradient_penalty\n",
    "\n",
    "    def train(self,data_loader,epochs):\n",
    "        '''训练模型'''\n",
    "        self.generated_images = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for i, (real_images, labels) in enumerate(data_loader):\n",
    "                real_images = real_images.cuda()\n",
    "                labels = labels.cuda()\n",
    "                batch_size = real_images.shape[0]\n",
    "\n",
    "                for j in range(CRITIC_STEPS):\n",
    "                    real_predictions,fake_predictions,fake_images = self.forward(real_images,labels)\n",
    "\n",
    "                    c_wass_loss = fake_predictions.mean() - real_predictions.mean()\n",
    "                    c_gp = self.gradient_penalty(real_images, fake_images, labels)\n",
    "                    c_loss = c_wass_loss + c_gp * GP_WEIGHT\n",
    "\n",
    "                    self.c_optimizer.zero_grad()\n",
    "                    c_loss.backward()\n",
    "                    self.c_optimizer.step()\n",
    "\n",
    "                real_predictions,fake_predictions,fake_images = self.forward(real_images,labels)\n",
    "                g_loss = -fake_predictions.mean()\n",
    "\n",
    "\n",
    "                self.g_optimizer.zero_grad()          \n",
    "                g_loss.backward()\n",
    "                self.g_optimizer.step()\n",
    "\n",
    "                # if i % 5 == 0:\n",
    "                #     print(f\"Epoch {epoch}, Batch {i}, D loss: {c_loss.item()}, G loss: {g_loss.item()}\")\n",
    "\n",
    "            # 每5个epoch生成并保存10张图像\n",
    "            if epoch % 5 == 0:\n",
    "                with torch.no_grad():\n",
    "                    generated_labels = torch.ones((10,1))\n",
    "                    fake_images = self.generator(torch.randn(10, self.latent_dim).cuda(),generated_labels.cuda())\n",
    "                    self.generated_images.append(fake_images)\n",
    "                print(f\"Epoch {epoch}, Batch {i}, D loss: {c_loss.item()}, G loss: {g_loss.item()}\")\n",
    "\n",
    "        # 训练结束后显示生成的图像\n",
    "        for i, images in enumerate(self.generated_images):\n",
    "            plt.figure(figsize=(10,10))\n",
    "            for j, image in enumerate(images):\n",
    "                plt.subplot(10, 10, j+1)\n",
    "                plt.imshow(image.cpu().detach().numpy().transpose(1, 2, 0)* 127.5 + 127.5)\n",
    "                plt.axis('off')\n",
    "            plt.show()\n",
    "    \n",
    "    def test(self,labels = 0):\n",
    "        '''测试模型'''\n",
    "        labels = torch.ones((10,1))*labels\n",
    "        fake_images = self.generator(torch.randn(10, self.latent_dim).cuda(), labels.cuda())\n",
    "        \n",
    "        fake_images = np.transpose(torch.squeeze(fake_images).cpu().detach().numpy(),(0,2,3,1))\n",
    "        display(fake_images, cmap=\"gray_r\", as_type=\"float32\")\n",
    "    \n",
    "    def save(self, filepath = 'model/conditional_wgan.pth'):\n",
    "        '''保存模型'''\n",
    "        torch.save({\n",
    "            'critic_state_dict': self.critic.state_dict(),\n",
    "            'generator_state_dict': self.generator.state_dict(),\n",
    "            'latent_dim': self.latent_dim,\n",
    "            'critic_step': self.critic_step,\n",
    "            'gp_weight': self.gp_weight,\n",
    "            'c_optimizer_state_dict': self.c_optimizer.state_dict(),\n",
    "            'g_optimizer_state_dict': self.g_optimizer.state_dict(),\n",
    "            'generated_images': self.generated_images\n",
    "        }, filepath)\n",
    "    \n",
    "    def load(self, filepath= 'model/conditional_wgan.pth'):\n",
    "        '''加载模型'''\n",
    "        checkpoint = torch.load(filepath)\n",
    "        self.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
    "        self.generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "        self.latent_dim = checkpoint['latent_dim']\n",
    "        self.critic_step = checkpoint['critic_step']\n",
    "        self.gp_weight = checkpoint['gp_weight']\n",
    "        self.c_optimizer.load_state_dict(checkpoint['c_optimizer_state_dict'])\n",
    "        self.g_optimizer.load_state_dict(checkpoint['g_optimizer_state_dict'])\n",
    "        self.generated_images = checkpoint['generated_images']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic = Critic().cuda()\n",
    "generator = Generator().cuda()\n",
    "cgan = ConditionalWGAN(critic, generator, Z_DIM, CRITIC_STEPS, GP_WEIGHT)\n",
    "cgan.train(train_loader, EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgan.save()\n",
    "# cgan.load()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgan.test(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
